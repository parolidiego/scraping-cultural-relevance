---
title: "The Guardian API"
author: "David Pereiro Pol"
date: "2025-03-16"
output: html_document
---

```{r}
# usethis::edit_r_environ()
# file.edit("~/.Renviron")
# Sys.getenv("API_KEY_GUARDIAN")

library(httr2)
library(tidyverse)
```

Only trying out

```{r}
main_link <- "https://content.guardianapis.com/search"

# Trying out a query to understand structure
data <- main_link |> 
  request() |>
  req_url_query(`api-key` = Sys.getenv("API_KEY_GUARDIAN"), format = "json",
                `from-date` = "2000-04-30", `to-date` = "2000-05-04", 
                `order-by` = "relevance", `section` = "world", 
                `show-fields` = "headline,trailText,standfirst",
                `page-size` = 50) |> 
  req_perform() |> 
  resp_body_json(simplifyVector = TRUE)

data$response$results$webTitle

news <- tibble(
  date = data$response$results$webPublicationDate,
  title = data$response$results$webTitle,
  subtitle = data$response$results$fields$trailText,
  standfirst = data$response$results$fields$standfirst,
  url = data$response$results$webUrl
)

news <- news |> 
  mutate(date = str_remove_all(date,"T.+00$"),
         date = as_date(date),
         rank = row_number()) |> 
  group_by(date) |> 
  slice_min(rank) |> 
  ungroup() |> 
  select(-rank)
```


Function to scrape

```{r}
# Create a function to get a list of start and end date for every query
dates_creator <- function(start, end) {
  # To be provided as "yyyy-mm-dd"
  
  start_dates <- seq(as.Date(start), as.Date(end), by="5 days")
  end_dates <- start_dates + 4
  
  start_dates <- start_dates |> 
    as.character() 
  
  end_dates <- end_dates |> 
    as.character() 
  
  list_dates <- list(start_dates, end_dates)
  
  return(list_dates)
}

# Apply function
dates <- dates_creator("2000-04-05", "2007-01-05")

start_dates <- dates[[1]]
start_dates
end_dates <- dates[[2]]
end_dates

guardian_news <- function(start_date, end_date){
  
  api_key <- Sys.getenv("API_KEY_GUARDIAN")
  if (api_key == "") stop("API key is missing! Set 'API_KEY_GUARDIAN' in your environment.")
   
  Sys.sleep(1)
  
  main_link <- "https://content.guardianapis.com/search"
  
  data <- main_link |> 
    request() |>
    req_url_query(`api-key` = Sys.getenv("API_KEY_GUARDIAN"), format = "json",
                `from-date` = start_date, `to-date` = end_date, 
                `order-by` = "relevance", `section` = "world", 
                `show-fields` = "headline,trailText,standfirst",
                `page-size` = 50) |>
    req_perform() |> 
    resp_body_json(simplifyVector = TRUE)
  
  news <- tibble(
    date = data$response$results$webPublicationDate,
    title = data$response$results$webTitle,
    subtitle = data$response$results$fields$trailText,
    standfirst = data$response$results$fields$standfirst,
    url = data$response$results$webUrl
  )
  
  news <- news |> 
    mutate(date = str_remove_all(date,"T.+$"))|> 
    mutate(date = str_trim(date)) |>     
    mutate(date = as_date(date)) |>  
    mutate(rank = row_number())  |> 
    group_by(date) |> 
    slice_min(rank, with_ties = FALSE) |> 
    ungroup() 
  
  return(news)
}

news <- map2_dfr(start_dates, end_dates, guardian_news)

if (!file.exists("data/guardian_database.csv")) {
    write_csv(news, "data/guardian_database.csv")
  } else {
    # If the file does exist, the *append* the result to the already existing CSV file
    write_csv(news, "data/guardian_database.csv", append = TRUE)
  }

```

